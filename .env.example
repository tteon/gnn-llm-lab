# GNN+LLM Experiment Environment Configuration
# Copy this file to .env and update with your values

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=finderlpg

# For Colab with ngrok tunnel:
# NEO4J_URI=bolt://0.tcp.jp.ngrok.io:XXXXX

# HuggingFace Token (required for Llama models)
# Get your token from: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_xxxxx

# OpenAI API Key (optional, for embedding alternatives)
# OPENAI_API_KEY=sk-xxxxx

# LLM API Configuration (for remote vLLM inference)
# LLM_API_BASE_URL=http://your-server:port/v1
# LLM_API_KEY=your-api-key
# LLM_API_MODEL=your-model-name

# Experiment Settings
LOG_LEVEL=INFO
EXPERIMENT_SEED=42
