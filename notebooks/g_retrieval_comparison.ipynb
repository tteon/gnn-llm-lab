{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G-Retrieval Style Comparison: LPG (GAT) vs RDF (TransE / DistMult)\n",
    "\n",
    "This notebook trains graph encoders on the FinDER dual-graph PyG dataset and evaluates\n",
    "how well learned graph embeddings capture answer-relevant information.\n",
    "\n",
    "**Models:**\n",
    "- **GAT** (Graph Attention Network) on LPG subgraphs — 384d node features + message passing\n",
    "- **TransE** on RDF triples — translation-based: h + r ≈ t (asymmetric)\n",
    "- **DistMult** on RDF triples — bilinear: h · diag(r) · t (symmetric)\n",
    "\n",
    "**Evaluation:**\n",
    "- Link prediction (self-supervised training objective)\n",
    "- Graph→Answer retrieval (cosine similarity with sentence embeddings)\n",
    "- Category-wise and graph-size breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup & Install\n# Uncomment for Colab:\n# !pip install torch torch-geometric sentence-transformers rouge-score\n# !pip install torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n\nimport sys, os, json, warnings\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams.update({'font.size': 11, 'figure.dpi': 120})\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom torch_geometric.nn import GATConv, global_mean_pool\nfrom torch_geometric.nn.kge import TransE, DistMult\nfrom torch_geometric.utils import negative_sampling, scatter\n\n# Project imports — adjust path for Colab\nPROJECT_ROOT = Path('..').resolve()\nif str(PROJECT_ROOT) not in sys.path:\n    sys.path.insert(0, str(PROJECT_ROOT))\n\nfrom src.data import FinDERGraphQADataset, DualGraphBatch, dual_graph_collate_fn, VocabularyBuilder\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Device: {device}')\nif device.type == 'cuda':\n    print(f'  GPU: {torch.cuda.get_device_name()}')\n    print(f'  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Loading\n",
    "DATA_ROOT = PROJECT_ROOT / 'data' / 'processed' / 'finder_pyg'\n",
    "\n",
    "train_ds = FinDERGraphQADataset(root=str(DATA_ROOT), split='train')\n",
    "val_ds   = FinDERGraphQADataset(root=str(DATA_ROOT), split='val')\n",
    "test_ds  = FinDERGraphQADataset(root=str(DATA_ROOT), split='test')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=dual_graph_collate_fn, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          collate_fn=dual_graph_collate_fn, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          collate_fn=dual_graph_collate_fn, num_workers=0)\n",
    "\n",
    "# Load vocabularies\n",
    "vocabs = FinDERGraphQADataset.get_vocab(root=str(DATA_ROOT))\n",
    "metadata = json.loads((DATA_ROOT / 'processed' / 'metadata.json').read_text())\n",
    "\n",
    "NUM_RDF_ENTITIES  = metadata['vocab_sizes']['rdf_entities']   # 17,534\n",
    "NUM_RDF_RELATIONS = metadata['vocab_sizes']['rdf_relations']  # 4,340\n",
    "LPG_FEATURE_DIM   = metadata['lpg_feature_dim']               # 384\n",
    "\n",
    "# Dataset statistics\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Dataset Statistics\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Train: {len(train_ds):,} | Val: {len(val_ds):,} | Test: {len(test_ds):,}\")\n",
    "print(f\"  LPG feature dim: {LPG_FEATURE_DIM}\")\n",
    "print(f\"  RDF entities: {NUM_RDF_ENTITIES:,} | relations: {NUM_RDF_RELATIONS:,}\")\n",
    "\n",
    "# Category distribution\n",
    "categories = [train_ds[i].category for i in range(len(train_ds))]\n",
    "cat_counts = pd.Series(categories).value_counts()\n",
    "print(f\"\\nCategory distribution (train):\")\n",
    "for cat, count in cat_counts.items():\n",
    "    print(f\"  {cat}: {count}\")\n",
    "\n",
    "# Average graph sizes\n",
    "lpg_nodes = [train_ds[i].lpg_num_nodes.item() for i in range(min(200, len(train_ds)))]\n",
    "rdf_edges = [train_ds[i].rdf_edge_index.shape[1] for i in range(min(200, len(train_ds)))]\n",
    "print(f\"\\nAvg LPG nodes/sample: {np.mean(lpg_nodes):.1f} (±{np.std(lpg_nodes):.1f})\")\n",
    "print(f\"Avg RDF triples/sample: {np.mean(rdf_edges):.1f} (±{np.std(rdf_edges):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Model Definitions\n\n# --- GAT for LPG (batched) ---\n\nclass BatchedGAT(nn.Module):\n    \"\"\"GAT encoder for LPG subgraphs with batched graph-level pooling.\n\n    Based on MessagePassingGNN from src/_legacy/models.py but uses\n    global_mean_pool for proper mini-batch support.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_dim: int = 384,\n        hidden_dim: int = 256,\n        output_dim: int = 384,\n        num_layers: int = 2,\n        heads: int = 4,\n        dropout: float = 0.1,\n    ):\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, hidden_dim)\n        self.convs = nn.ModuleList()\n        self.norms = nn.ModuleList()\n        for i in range(num_layers):\n            in_ch = hidden_dim if i == 0 else hidden_dim * heads\n            self.convs.append(GATConv(in_ch, hidden_dim, heads=heads, dropout=dropout))\n            self.norms.append(nn.LayerNorm(hidden_dim * heads))\n        self.output_proj = nn.Linear(hidden_dim * heads, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, edge_index, batch):\n        \"\"\"Forward pass with batched graph-level pooling.\n\n        Args:\n            x: [sum(N_i), input_dim] node features\n            edge_index: [2, sum(E_i)] COO edges\n            batch: [sum(N_i)] graph membership index\n\n        Returns:\n            [B, output_dim] graph-level embeddings\n        \"\"\"\n        x = torch.relu(self.input_proj(x))\n        for conv, norm in zip(self.convs, self.norms):\n            x = conv(x, edge_index)\n            x = norm(x)\n            x = torch.relu(x)\n            x = self.dropout(x)\n        node_emb = self.output_proj(x)  # [sum(N_i), output_dim]\n        return global_mean_pool(node_emb, batch)  # [B, output_dim]\n\n    def get_node_embeddings(self, x, edge_index):\n        \"\"\"Get per-node embeddings (no pooling). For link prediction decoding.\"\"\"\n        x = torch.relu(self.input_proj(x))\n        for conv, norm in zip(self.convs, self.norms):\n            x = conv(x, edge_index)\n            x = norm(x)\n            x = torch.relu(x)\n            x = self.dropout(x)\n        return self.output_proj(x)  # [sum(N_i), output_dim]\n\n\n# --- KGE for RDF (TransE / DistMult) with per-graph aggregation ---\n\nclass BatchedKGE(nn.Module):\n    \"\"\"KGE encoder for RDF triples with per-graph embedding aggregation.\n\n    Learns global entity and relation embeddings, then for each question's\n    RDF subgraph, aggregates triple representations via scatter mean.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_type: str,  # 'transe' or 'distmult'\n        num_entities: int,\n        num_relations: int,\n        hidden_dim: int = 256,\n        output_dim: int = 384,\n    ):\n        super().__init__()\n        self.model_type = model_type\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n\n        if model_type == 'transe':\n            self.kge = TransE(\n                num_nodes=num_entities,\n                num_relations=num_relations,\n                hidden_channels=hidden_dim,\n                margin=1.0,\n                p_norm=1.0,\n            )\n        elif model_type == 'distmult':\n            self.kge = DistMult(\n                num_nodes=num_entities,\n                num_relations=num_relations,\n                hidden_channels=hidden_dim,\n            )\n        else:\n            raise ValueError(f\"Unknown model_type: {model_type}\")\n\n        self.output_proj = nn.Linear(hidden_dim, output_dim)\n\n    def loss(self, head_index, rel_type, tail_index):\n        \"\"\"KGE training loss with built-in negative sampling.\"\"\"\n        return self.kge.loss(head_index, rel_type, tail_index)\n\n    def forward(self, batch: 'DualGraphBatch'):\n        \"\"\"Compute per-graph embeddings from RDF triples.\n\n        For each triple (h, r, t) in the batch, computes h_emb + r_emb,\n        then aggregates per-graph via scatter mean on the head node's\n        graph membership.\n\n        Returns:\n            [B, output_dim] graph-level embeddings\n        \"\"\"\n        edge_index = batch.rdf_edge_index  # [2, sum(T_i)]\n        edge_type = batch.rdf_edge_type    # [sum(T_i)]\n        rdf_batch = batch.rdf_batch        # [sum(N_rdf_i)]\n        global_idx = batch.rdf_global_node_idx  # [sum(N_rdf_i)]\n\n        if edge_index.shape[1] == 0:\n            return torch.zeros(batch.batch_size, self.output_dim, device=edge_index.device)\n\n        head_local = edge_index[0]  # local node indices\n        tail_local = edge_index[1]\n\n        # Map local indices to global for embedding lookup\n        head_global = global_idx[head_local]\n        tail_global = global_idx[tail_local]\n\n        head_emb = self.kge.node_emb(head_global)  # [sum(T_i), hidden_dim]\n        rel_emb = self.kge.rel_emb(edge_type)       # [sum(T_i), hidden_dim]\n\n        # Triple representation: h + r (translation-style, works for both)\n        triple_emb = head_emb + rel_emb  # [sum(T_i), hidden_dim]\n\n        # Determine graph membership for each triple (from head node)\n        triple_graph = rdf_batch[head_local]  # [sum(T_i)]\n\n        # Aggregate triples per graph (using PyG's scatter with reduce='mean')\n        graph_emb = scatter(triple_emb, triple_graph, dim=0,\n                            dim_size=batch.batch_size, reduce='mean')  # [B, hidden_dim]\n\n        return self.output_proj(graph_emb)  # [B, output_dim]\n\n    def get_entity_embeddings(self):\n        \"\"\"Export projected entity embeddings [num_entities, output_dim].\"\"\"\n        with torch.no_grad():\n            return self.output_proj(self.kge.node_emb.weight)\n\n\n# Quick sanity check\nprint('BatchedGAT params:', sum(p.numel() for p in BatchedGAT().parameters()) / 1e3, 'K')\nprint('BatchedKGE (TransE) params:',\n      sum(p.numel() for p in BatchedKGE('transe', NUM_RDF_ENTITIES, NUM_RDF_RELATIONS).parameters()) / 1e6, 'M')\nprint('BatchedKGE (DistMult) params:',\n      sum(p.numel() for p in BatchedKGE('distmult', NUM_RDF_ENTITIES, NUM_RDF_RELATIONS).parameters()) / 1e6, 'M')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Training — GAT (LPG) via Link Prediction\n",
    "\n",
    "def train_gat_epoch(model, loader, optimizer):\n",
    "    \"\"\"Train GAT via link prediction with negative sampling.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get node embeddings (no pooling)\n",
    "        z = model.get_node_embeddings(batch.lpg_x, batch.lpg_edge_index)\n",
    "\n",
    "        # Positive edges\n",
    "        pos_edge = batch.lpg_edge_index\n",
    "        num_nodes = batch.lpg_x.shape[0]\n",
    "\n",
    "        if pos_edge.shape[1] == 0:\n",
    "            continue\n",
    "\n",
    "        # Negative sampling\n",
    "        neg_edge = negative_sampling(\n",
    "            pos_edge, num_nodes=num_nodes,\n",
    "            num_neg_samples=pos_edge.shape[1],\n",
    "        )\n",
    "\n",
    "        # Score positive and negative edges via dot product\n",
    "        pos_score = (z[pos_edge[0]] * z[pos_edge[1]]).sum(dim=-1)\n",
    "        neg_score = (z[neg_edge[0]] * z[neg_edge[1]]).sum(dim=-1)\n",
    "\n",
    "        # BCE loss\n",
    "        pos_loss = F.binary_cross_entropy_with_logits(pos_score, torch.ones_like(pos_score))\n",
    "        neg_loss = F.binary_cross_entropy_with_logits(neg_score, torch.zeros_like(neg_score))\n",
    "        loss = pos_loss + neg_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_gat_link_prediction(model, loader):\n",
    "    \"\"\"Evaluate GAT link prediction: MRR and Hits@10.\"\"\"\n",
    "    model.eval()\n",
    "    mrr_sum, hits10_sum, count = 0.0, 0.0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        z = model.get_node_embeddings(batch.lpg_x, batch.lpg_edge_index)\n",
    "\n",
    "        pos_edge = batch.lpg_edge_index\n",
    "        if pos_edge.shape[1] == 0:\n",
    "            continue\n",
    "\n",
    "        num_nodes = z.shape[0]\n",
    "        # Score a sample of edges (full ranking is too slow)\n",
    "        sample_size = min(500, pos_edge.shape[1])\n",
    "        idx = torch.randperm(pos_edge.shape[1])[:sample_size]\n",
    "        src, dst = pos_edge[0, idx], pos_edge[1, idx]\n",
    "\n",
    "        for s, d in zip(src, dst):\n",
    "            # Score true tail vs all nodes\n",
    "            scores = (z[s].unsqueeze(0) * z).sum(dim=-1)  # [num_nodes]\n",
    "            rank = (scores >= scores[d]).sum().item()\n",
    "            mrr_sum += 1.0 / rank\n",
    "            hits10_sum += 1.0 if rank <= 10 else 0.0\n",
    "            count += 1\n",
    "\n",
    "    mrr = mrr_sum / max(count, 1)\n",
    "    hits10 = hits10_sum / max(count, 1)\n",
    "    return {'mrr': mrr, 'hits@10': hits10}\n",
    "\n",
    "\n",
    "# Train GAT\n",
    "GAT_EPOCHS = 50\n",
    "GAT_LR = 1e-3\n",
    "\n",
    "gat_model = BatchedGAT(input_dim=LPG_FEATURE_DIM).to(device)\n",
    "gat_optimizer = torch.optim.Adam(gat_model.parameters(), lr=GAT_LR, weight_decay=1e-5)\n",
    "\n",
    "gat_history = {'train_loss': [], 'val_mrr': [], 'val_hits10': []}\n",
    "best_val_mrr = 0.0\n",
    "best_gat_state = None\n",
    "\n",
    "print(f'Training GAT for {GAT_EPOCHS} epochs...')\n",
    "for epoch in range(1, GAT_EPOCHS + 1):\n",
    "    loss = train_gat_epoch(gat_model, train_loader, gat_optimizer)\n",
    "    gat_history['train_loss'].append(loss)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        val_metrics = eval_gat_link_prediction(gat_model, val_loader)\n",
    "        gat_history['val_mrr'].append(val_metrics['mrr'])\n",
    "        gat_history['val_hits10'].append(val_metrics['hits@10'])\n",
    "        print(f'  Epoch {epoch:3d} | Loss: {loss:.4f} | Val MRR: {val_metrics[\"mrr\"]:.4f} | Val Hits@10: {val_metrics[\"hits@10\"]:.3f}')\n",
    "\n",
    "        if val_metrics['mrr'] > best_val_mrr:\n",
    "            best_val_mrr = val_metrics['mrr']\n",
    "            best_gat_state = {k: v.cpu().clone() for k, v in gat_model.state_dict().items()}\n",
    "\n",
    "# Restore best model\n",
    "if best_gat_state:\n",
    "    gat_model.load_state_dict(best_gat_state)\n",
    "    gat_model.to(device)\n",
    "print(f'\\nBest GAT Val MRR: {best_val_mrr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Training — TransE & DistMult (RDF)\n",
    "\n",
    "def collect_all_rdf_triples(loader):\n",
    "    \"\"\"Collect all (head_global, rel, tail_global) triples from the dataset.\"\"\"\n",
    "    heads, rels, tails = [], [], []\n",
    "    for batch in loader:\n",
    "        ei = batch.rdf_edge_index\n",
    "        et = batch.rdf_edge_type\n",
    "        gi = batch.rdf_global_node_idx\n",
    "        if ei.shape[1] == 0:\n",
    "            continue\n",
    "        heads.append(gi[ei[0]])\n",
    "        tails.append(gi[ei[1]])\n",
    "        rels.append(et)\n",
    "    return torch.cat(heads), torch.cat(rels), torch.cat(tails)\n",
    "\n",
    "\n",
    "def train_kge_epoch(model, head, rel, tail, optimizer, batch_size=512):\n",
    "    \"\"\"Train KGE model for one epoch over all triples.\"\"\"\n",
    "    model.train()\n",
    "    perm = torch.randperm(head.shape[0], device=head.device)\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for i in range(0, head.shape[0], batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(head[idx], rel[idx], tail[idx])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_kge(model, head, rel, tail, sample_size=1000, k=10):\n",
    "    \"\"\"Evaluate KGE with sampled ranking: MRR and Hits@K.\"\"\"\n",
    "    model.eval()\n",
    "    n = min(sample_size, head.shape[0])\n",
    "    idx = torch.randperm(head.shape[0])[:n]\n",
    "    h, r, t = head[idx], rel[idx], tail[idx]\n",
    "\n",
    "    node_emb = model.kge.node_emb.weight  # [num_entities, hidden_dim]\n",
    "    rel_emb = model.kge.rel_emb(r)        # [n, hidden_dim]\n",
    "    h_emb = model.kge.node_emb(h)          # [n, hidden_dim]\n",
    "\n",
    "    mrr_sum, hits_sum = 0.0, 0.0\n",
    "\n",
    "    for i in range(n):\n",
    "        if model.model_type == 'transe':\n",
    "            # score = -||h + r - t||  (higher = better)\n",
    "            pred = h_emb[i] + rel_emb[i]  # [hidden_dim]\n",
    "            scores = -torch.norm(node_emb - pred.unsqueeze(0), p=1, dim=-1)  # [num_entities]\n",
    "        else:  # distmult\n",
    "            # score = sum(h * r * t)\n",
    "            pred = h_emb[i] * rel_emb[i]  # [hidden_dim]\n",
    "            scores = (node_emb * pred.unsqueeze(0)).sum(dim=-1)  # [num_entities]\n",
    "\n",
    "        rank = (scores >= scores[t[i]]).sum().item()\n",
    "        mrr_sum += 1.0 / max(rank, 1)\n",
    "        hits_sum += 1.0 if rank <= k else 0.0\n",
    "\n",
    "    return {'mrr': mrr_sum / n, f'hits@{k}': hits_sum / n}\n",
    "\n",
    "\n",
    "# Collect triples\n",
    "print('Collecting RDF triples...')\n",
    "train_h, train_r, train_t = collect_all_rdf_triples(train_loader)\n",
    "val_h, val_r, val_t = collect_all_rdf_triples(val_loader)\n",
    "train_h, train_r, train_t = train_h.to(device), train_r.to(device), train_t.to(device)\n",
    "val_h, val_r, val_t = val_h.to(device), val_r.to(device), val_t.to(device)\n",
    "print(f'  Train triples: {train_h.shape[0]:,} | Val triples: {val_h.shape[0]:,}')\n",
    "\n",
    "# Train both models\n",
    "KGE_EPOCHS = 100\n",
    "KGE_LR = 1e-2\n",
    "KGE_BATCH = 512\n",
    "\n",
    "kge_models = {}\n",
    "kge_histories = {}\n",
    "\n",
    "for model_type in ['transe', 'distmult']:\n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print(f'Training {model_type.upper()} for {KGE_EPOCHS} epochs...')\n",
    "    print(f'{\"=\"*50}')\n",
    "\n",
    "    model = BatchedKGE(model_type, NUM_RDF_ENTITIES, NUM_RDF_RELATIONS).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=KGE_LR)\n",
    "    history = {'train_loss': [], 'val_mrr': [], 'val_hits10': []}\n",
    "    best_mrr = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, KGE_EPOCHS + 1):\n",
    "        loss = train_kge_epoch(model, train_h, train_r, train_t, optimizer, KGE_BATCH)\n",
    "        history['train_loss'].append(loss)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            val_metrics = eval_kge(model, val_h, val_r, val_t)\n",
    "            history['val_mrr'].append(val_metrics['mrr'])\n",
    "            history['val_hits10'].append(val_metrics['hits@10'])\n",
    "            print(f'  Epoch {epoch:3d} | Loss: {loss:.4f} | Val MRR: {val_metrics[\"mrr\"]:.4f} | Val Hits@10: {val_metrics[\"hits@10\"]:.3f}')\n",
    "\n",
    "            if val_metrics['mrr'] > best_mrr:\n",
    "                best_mrr = val_metrics['mrr']\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "        model.to(device)\n",
    "    print(f'Best {model_type.upper()} Val MRR: {best_mrr:.4f}')\n",
    "\n",
    "    kge_models[model_type] = model\n",
    "    kge_histories[model_type] = history\n",
    "\n",
    "# Loss curve comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for mt, h in kge_histories.items():\n",
    "    axes[0].plot(h['train_loss'], label=mt.upper())\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('KGE Training Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Also plot GAT loss\n",
    "axes[1].plot(gat_history['train_loss'], label='GAT', color='tab:green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('GAT Training Loss')\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Graph Embedding Extraction\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(gat_model, kge_models, loader):\n",
    "    \"\"\"Extract per-question graph embeddings from all models.\n",
    "\n",
    "    Returns dict with:\n",
    "        'gat': [N, 384] LPG-GAT embeddings\n",
    "        'transe': [N, 384] RDF-TransE embeddings\n",
    "        'distmult': [N, 384] RDF-DistMult embeddings\n",
    "        'questions': list of question strings\n",
    "        'answers': list of answer strings\n",
    "        'question_ids': list of question IDs\n",
    "        'categories': list of category strings\n",
    "    \"\"\"\n",
    "    gat_model.eval()\n",
    "    for m in kge_models.values():\n",
    "        m.eval()\n",
    "\n",
    "    all_gat, all_transe, all_distmult = [], [], []\n",
    "    all_questions, all_answers, all_qids, all_cats = [], [], [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch_gpu = batch.to(device)\n",
    "\n",
    "        # GAT embedding\n",
    "        gat_emb = gat_model(batch_gpu.lpg_x, batch_gpu.lpg_edge_index, batch_gpu.lpg_batch)\n",
    "        all_gat.append(gat_emb.cpu())\n",
    "\n",
    "        # KGE embeddings\n",
    "        for name, model in kge_models.items():\n",
    "            emb = model(batch_gpu)\n",
    "            if name == 'transe':\n",
    "                all_transe.append(emb.cpu())\n",
    "            else:\n",
    "                all_distmult.append(emb.cpu())\n",
    "\n",
    "        all_questions.extend(batch.questions)\n",
    "        all_answers.extend(batch.answers)\n",
    "        all_qids.extend(batch.question_ids)\n",
    "        all_cats.extend(batch.categories)\n",
    "\n",
    "    return {\n",
    "        'gat': F.normalize(torch.cat(all_gat, dim=0), dim=-1),\n",
    "        'transe': F.normalize(torch.cat(all_transe, dim=0), dim=-1),\n",
    "        'distmult': F.normalize(torch.cat(all_distmult, dim=0), dim=-1),\n",
    "        'questions': all_questions,\n",
    "        'answers': all_answers,\n",
    "        'question_ids': all_qids,\n",
    "        'categories': all_cats,\n",
    "    }\n",
    "\n",
    "\n",
    "print('Extracting embeddings...')\n",
    "train_emb = extract_embeddings(gat_model, kge_models, train_loader)\n",
    "val_emb   = extract_embeddings(gat_model, kge_models, val_loader)\n",
    "test_emb  = extract_embeddings(gat_model, kge_models, test_loader)\n",
    "\n",
    "print(f'  Train: {train_emb[\"gat\"].shape[0]} samples')\n",
    "print(f'  Val:   {val_emb[\"gat\"].shape[0]} samples')\n",
    "print(f'  Test:  {test_emb[\"gat\"].shape[0]} samples')\n",
    "print(f'  Embedding dim: {train_emb[\"gat\"].shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Question-Answer Embedding Baseline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2', device=str(device))\n",
    "\n",
    "\n",
    "def encode_texts(texts, batch_size=64):\n",
    "    \"\"\"Encode texts with sentence-transformers → [N, 384] normalized.\"\"\"\n",
    "    embs = st_model.encode(texts, batch_size=batch_size, show_progress_bar=False,\n",
    "                           convert_to_tensor=True, normalize_embeddings=True)\n",
    "    return embs.cpu()\n",
    "\n",
    "\n",
    "print('Encoding answers with sentence-transformers...')\n",
    "test_answer_emb = encode_texts(test_emb['answers'])\n",
    "test_question_emb = encode_texts(test_emb['questions'])\n",
    "\n",
    "# Quick check: cosine similarity between graph embeddings and answer embeddings\n",
    "print('\\nMean cosine similarity (graph_emb · answer_emb):')\n",
    "for name in ['gat', 'transe', 'distmult']:\n",
    "    cos_sim = (test_emb[name] * test_answer_emb).sum(dim=-1).mean().item()\n",
    "    print(f'  {name:10s}: {cos_sim:.4f}')\n",
    "\n",
    "# Baseline: question-only embedding\n",
    "q_cos = (test_question_emb * test_answer_emb).sum(dim=-1).mean().item()\n",
    "print(f'  {\"question\":10s}: {q_cos:.4f} (text-only baseline)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Retrieval Evaluation\n",
    "\n",
    "def retrieval_eval(query_emb, corpus_emb, ks=(1, 5, 10)):\n",
    "    \"\"\"Compute retrieval metrics: Recall@K and MRR.\n",
    "\n",
    "    Each query[i] should retrieve corpus[i] (diagonal = ground truth).\n",
    "\n",
    "    Args:\n",
    "        query_emb: [N, D] query embeddings (graph or question)\n",
    "        corpus_emb: [N, D] corpus embeddings (answers)\n",
    "        ks: tuple of K values for Recall@K\n",
    "\n",
    "    Returns:\n",
    "        dict with 'mrr' and 'recall@k' for each k\n",
    "    \"\"\"\n",
    "    # Similarity matrix [N, N]\n",
    "    sim = query_emb @ corpus_emb.T\n",
    "    N = sim.shape[0]\n",
    "\n",
    "    # Rank of the correct answer (diagonal)\n",
    "    diag = sim.diag().unsqueeze(1)  # [N, 1]\n",
    "    ranks = (sim >= diag).sum(dim=1).float()  # [N] — 1-based rank\n",
    "\n",
    "    results = {'mrr': (1.0 / ranks).mean().item()}\n",
    "    for k in ks:\n",
    "        results[f'recall@{k}'] = (ranks <= k).float().mean().item()\n",
    "    return results\n",
    "\n",
    "\n",
    "# Evaluate all models\n",
    "print(f'{\"Model\":<12} {\"MRR\":>8} {\"R@1\":>8} {\"R@5\":>8} {\"R@10\":>8}')\n",
    "print('-' * 48)\n",
    "\n",
    "retrieval_results = {}\n",
    "for name in ['gat', 'transe', 'distmult']:\n",
    "    r = retrieval_eval(test_emb[name], test_answer_emb)\n",
    "    retrieval_results[name] = r\n",
    "    print(f'{name:<12} {r[\"mrr\"]:8.4f} {r[\"recall@1\"]:8.4f} {r[\"recall@5\"]:8.4f} {r[\"recall@10\"]:8.4f}')\n",
    "\n",
    "# Baseline: question text → answer text retrieval\n",
    "r_baseline = retrieval_eval(test_question_emb, test_answer_emb)\n",
    "retrieval_results['question'] = r_baseline\n",
    "print(f'{\"question\":<12} {r_baseline[\"mrr\"]:8.4f} {r_baseline[\"recall@1\"]:8.4f} {r_baseline[\"recall@5\"]:8.4f} {r_baseline[\"recall@10\"]:8.4f}')\n",
    "print('  (question = text-only baseline, no graph)')\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "models = list(retrieval_results.keys())\n",
    "metrics = ['mrr', 'recall@1', 'recall@5', 'recall@10']\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "for i, m in enumerate(metrics):\n",
    "    vals = [retrieval_results[model][m] for model in models]\n",
    "    ax.bar(x + i * width, vals, width, label=m.upper())\n",
    "\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels([m.upper() for m in models])\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Graph → Answer Retrieval Performance')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Category-wise Analysis\n",
    "\n",
    "def category_retrieval_eval(emb_dict, answer_emb, categories):\n",
    "    \"\"\"Evaluate retrieval per category.\n",
    "\n",
    "    Returns DataFrame: rows=categories, columns=model×metric.\n",
    "    \"\"\"\n",
    "    cats = sorted(set(categories))\n",
    "    cat_array = np.array(categories)\n",
    "    rows = []\n",
    "\n",
    "    for cat in cats:\n",
    "        mask = cat_array == cat\n",
    "        n = mask.sum()\n",
    "        if n < 2:\n",
    "            continue\n",
    "        indices = np.where(mask)[0]\n",
    "\n",
    "        row = {'category': cat, 'n': int(n)}\n",
    "        for model_name in ['gat', 'transe', 'distmult']:\n",
    "            q_emb = emb_dict[model_name][indices]\n",
    "            a_emb = answer_emb[indices]\n",
    "            r = retrieval_eval(q_emb, a_emb)\n",
    "            for metric, val in r.items():\n",
    "                row[f'{model_name}_{metric}'] = val\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "cat_df = category_retrieval_eval(test_emb, test_answer_emb, test_emb['categories'])\n",
    "print('Category-wise MRR:')\n",
    "print(cat_df[['category', 'n', 'gat_mrr', 'transe_mrr', 'distmult_mrr']].to_string(index=False))\n",
    "\n",
    "# Bar chart: category × model MRR\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "cats = cat_df['category'].values\n",
    "x = np.arange(len(cats))\n",
    "width = 0.25\n",
    "\n",
    "for i, model in enumerate(['gat', 'transe', 'distmult']):\n",
    "    vals = cat_df[f'{model}_mrr'].values\n",
    "    ax.bar(x + i * width, vals, width, label=model.upper())\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(cats, rotation=30, ha='right')\n",
    "ax.set_ylabel('MRR')\n",
    "ax.set_title('Category-wise Graph → Answer Retrieval MRR')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap: model advantage per category\n",
    "print('\\nBest model per category (MRR):')\n",
    "for _, row in cat_df.iterrows():\n",
    "    mrrs = {m: row[f'{m}_mrr'] for m in ['gat', 'transe', 'distmult']}\n",
    "    best = max(mrrs, key=mrrs.get)\n",
    "    print(f'  {row[\"category\"]:25s} → {best.upper()} ({mrrs[best]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Graph Size Effect\n",
    "\n",
    "def compute_per_sample_rank(query_emb, corpus_emb):\n",
    "    \"\"\"Compute rank of correct answer for each sample.\"\"\"\n",
    "    sim = query_emb @ corpus_emb.T\n",
    "    diag = sim.diag().unsqueeze(1)\n",
    "    ranks = (sim >= diag).sum(dim=1).float()\n",
    "    return ranks.numpy()\n",
    "\n",
    "\n",
    "# Collect graph sizes from test set\n",
    "test_lpg_nodes = []\n",
    "test_lpg_edges = []\n",
    "test_rdf_triples = []\n",
    "\n",
    "for i in range(len(test_ds)):\n",
    "    d = test_ds[i]\n",
    "    test_lpg_nodes.append(d.lpg_num_nodes.item())\n",
    "    test_lpg_edges.append(d.lpg_edge_index.shape[1])\n",
    "    test_rdf_triples.append(d.rdf_edge_index.shape[1])\n",
    "\n",
    "test_lpg_nodes = np.array(test_lpg_nodes)\n",
    "test_lpg_edges = np.array(test_lpg_edges)\n",
    "test_rdf_triples = np.array(test_rdf_triples)\n",
    "\n",
    "# Compute per-sample reciprocal rank\n",
    "rr = {}\n",
    "for name in ['gat', 'transe', 'distmult']:\n",
    "    ranks = compute_per_sample_rank(test_emb[name], test_answer_emb)\n",
    "    rr[name] = 1.0 / ranks\n",
    "\n",
    "# Scatter plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "\n",
    "for ax, (name, size_arr, size_label) in zip(axes, [\n",
    "    ('gat', test_lpg_nodes, 'LPG Nodes'),\n",
    "    ('transe', test_rdf_triples, 'RDF Triples'),\n",
    "    ('distmult', test_rdf_triples, 'RDF Triples'),\n",
    "]):\n",
    "    ax.scatter(size_arr, rr[name], alpha=0.3, s=10)\n",
    "    ax.set_xlabel(size_label)\n",
    "    ax.set_ylabel('Reciprocal Rank')\n",
    "    ax.set_title(f'{name.upper()}')\n",
    "\n",
    "    # Trend line via binning\n",
    "    bins = np.percentile(size_arr, np.linspace(0, 100, 11))\n",
    "    bins = np.unique(bins)\n",
    "    if len(bins) >= 2:\n",
    "        bin_idx = np.digitize(size_arr, bins) - 1\n",
    "        bin_idx = np.clip(bin_idx, 0, len(bins) - 2)\n",
    "        bin_centers = []\n",
    "        bin_means = []\n",
    "        for b in range(len(bins) - 1):\n",
    "            mask = bin_idx == b\n",
    "            if mask.sum() > 0:\n",
    "                bin_centers.append((bins[b] + bins[b+1]) / 2)\n",
    "                bin_means.append(rr[name][mask].mean())\n",
    "        ax.plot(bin_centers, bin_means, 'r-o', linewidth=2, markersize=4, label='Binned mean')\n",
    "        ax.legend()\n",
    "\n",
    "plt.suptitle('Graph Size vs Retrieval Quality', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation\n",
    "print('Spearman correlation (graph size vs reciprocal rank):')\n",
    "from scipy.stats import spearmanr\n",
    "for name, sizes in [('gat', test_lpg_nodes), ('transe', test_rdf_triples), ('distmult', test_rdf_triples)]:\n",
    "    corr, pval = spearmanr(sizes, rr[name])\n",
    "    print(f'  {name:10s}: rho={corr:.3f}, p={pval:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: TransE vs DistMult Deep Dive\n",
    "\n",
    "# 1. Loss curve comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(kge_histories['transe']['train_loss'], label='TransE')\n",
    "axes[0].plot(kge_histories['distmult']['train_loss'], label='DistMult')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss Comparison')\n",
    "axes[0].legend()\n",
    "\n",
    "# Val MRR over time\n",
    "eval_epochs_kge = [e for e in range(1, KGE_EPOCHS+1) if e % 10 == 0 or e == 1]\n",
    "for mt in ['transe', 'distmult']:\n",
    "    n = len(kge_histories[mt]['val_mrr'])\n",
    "    axes[1].plot(eval_epochs_kge[:n], kge_histories[mt]['val_mrr'][:n], '-o', label=mt.upper())\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Val MRR')\n",
    "axes[1].set_title('Validation MRR Over Training')\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. Per-sample comparison: where does one beat the other?\n",
    "transe_rr = rr['transe']\n",
    "distmult_rr = rr['distmult']\n",
    "diff = transe_rr - distmult_rr  # positive = TransE better\n",
    "\n",
    "transe_wins = (diff > 0).sum()\n",
    "distmult_wins = (diff < 0).sum()\n",
    "ties = (diff == 0).sum()\n",
    "print(f'Per-sample comparison (test set, N={len(diff)}):')\n",
    "print(f'  TransE wins:  {transe_wins} ({100*transe_wins/len(diff):.1f}%)')\n",
    "print(f'  DistMult wins: {distmult_wins} ({100*distmult_wins/len(diff):.1f}%)')\n",
    "print(f'  Ties:         {ties} ({100*ties/len(diff):.1f}%)')\n",
    "\n",
    "\n",
    "# 3. Category-level TransE vs DistMult advantage\n",
    "print('\\nCategory-level advantage (MRR difference = TransE - DistMult):')\n",
    "for _, row in cat_df.iterrows():\n",
    "    delta = row['transe_mrr'] - row['distmult_mrr']\n",
    "    arrow = '→ TransE' if delta > 0 else '→ DistMult'\n",
    "    print(f'  {row[\"category\"]:25s}: {delta:+.4f} {arrow}')\n",
    "\n",
    "\n",
    "# 4. t-SNE visualization of embedding spaces\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Use test set embeddings (subsample if needed)\n",
    "n_vis = min(300, test_emb['gat'].shape[0])\n",
    "vis_idx = np.random.choice(test_emb['gat'].shape[0], n_vis, replace=False)\n",
    "vis_cats = np.array(test_emb['categories'])[vis_idx]\n",
    "unique_cats = sorted(set(vis_cats))\n",
    "cat_colors = {c: plt.cm.tab10(i) for i, c in enumerate(unique_cats)}\n",
    "colors = [cat_colors[c] for c in vis_cats]\n",
    "\n",
    "for ax, name in zip(axes, ['gat', 'transe', 'distmult']):\n",
    "    emb = test_emb[name][vis_idx].numpy()\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    proj = tsne.fit_transform(emb)\n",
    "\n",
    "    for cat in unique_cats:\n",
    "        mask = vis_cats == cat\n",
    "        ax.scatter(proj[mask, 0], proj[mask, 1], c=[cat_colors[cat]],\n",
    "                   s=15, alpha=0.6, label=cat[:15])\n",
    "    ax.set_title(f'{name.upper()} Embedding Space')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "plt.suptitle('t-SNE of Graph Embeddings (colored by category)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Summary & Conclusions\n",
    "\n",
    "print('=' * 60)\n",
    "print('SUMMARY: G-Retrieval Style Comparison')\n",
    "print('=' * 60)\n",
    "\n",
    "# Overall retrieval results table\n",
    "results_df = pd.DataFrame([\n",
    "    {'model': name, **metrics}\n",
    "    for name, metrics in retrieval_results.items()\n",
    "    if name != 'question'\n",
    "])\n",
    "print('\\n--- Graph → Answer Retrieval (Test Set) ---')\n",
    "print(results_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Best model\n",
    "best_model = results_df.loc[results_df['mrr'].idxmax(), 'model']\n",
    "print(f'\\nBest overall model: {best_model.upper()} (MRR={results_df[\"mrr\"].max():.4f})')\n",
    "\n",
    "# Category breakdown summary\n",
    "print('\\n--- Best Model per Category (MRR) ---')\n",
    "category_results = []\n",
    "for _, row in cat_df.iterrows():\n",
    "    mrrs = {m: row[f'{m}_mrr'] for m in ['gat', 'transe', 'distmult']}\n",
    "    best = max(mrrs, key=mrrs.get)\n",
    "    category_results.append({'category': row['category'], 'best_model': best,\n",
    "                             'mrr': mrrs[best], 'n': row['n']})\n",
    "    print(f'  {row[\"category\"]:25s} → {best.upper():10s} (MRR={mrrs[best]:.4f}, n={int(row[\"n\"])})')\n",
    "\n",
    "category_results = pd.DataFrame(category_results)\n",
    "\n",
    "# Model strengths\n",
    "print('\\n--- Model Strengths & Weaknesses ---')\n",
    "print('GAT (LPG):      Pre-computed 384d node features + message passing.')\n",
    "print('                 Best for: categories with rich LPG structure.')\n",
    "print('TransE (RDF):    Translation h+r≈t. Asymmetric, handles directed relations.')\n",
    "print('                 Best for: categories with directional relationships (OWNS, REPORTED).')\n",
    "print('DistMult (RDF):  Bilinear h·r·t. Symmetric, simpler training dynamics.')\n",
    "print('                 Best for: symmetric or co-occurrence patterns.')\n",
    "\n",
    "# Verification assertions\n",
    "assert len(results_df) == 3, f'Expected 3 models, got {len(results_df)}'\n",
    "assert all(col in results_df.columns for col in ['model', 'mrr', 'recall@1', 'recall@5'])\n",
    "assert len(category_results) >= 1, 'No category results'\n",
    "print(f'\\nVerification passed: {len(results_df)} models, {len(category_results)} categories.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}